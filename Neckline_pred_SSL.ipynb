{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory 'D:/Jupyter_projects/Hey-Savi_assignment/fashion-dataset' found.\n",
      "Contents of the data directory: ['images', 'images.csv', 'styles', 'styles.csv']\n",
      "\n",
      "Dataset loaded successfully after skipping problematic rows.\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44424 entries, 0 to 44423\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  44424 non-null  int64  \n",
      " 1   gender              44424 non-null  object \n",
      " 2   masterCategory      44424 non-null  object \n",
      " 3   subCategory         44424 non-null  object \n",
      " 4   articleType         44424 non-null  object \n",
      " 5   baseColour          44409 non-null  object \n",
      " 6   season              44403 non-null  object \n",
      " 7   year                44423 non-null  float64\n",
      " 8   usage               44107 non-null  object \n",
      " 9   productDisplayName  44417 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 3.4+ MB\n",
      "\n",
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "     year   usage                             productDisplayName  \n",
       "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
       "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
       "2  2016.0  Casual                       Titan Women Silver Watch  \n",
       "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
       "4  2012.0  Casual                          Puma Men Grey T-shirt  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the working directory\n",
    "data_directory = \"D:/Jupyter_projects/Hey-Savi_assignment/fashion-dataset\"\n",
    "\n",
    "if os.path.exists(data_directory):\n",
    "    print(f\"Data directory '{data_directory}' found.\")\n",
    "    print(\"Contents of the data directory:\", os.listdir(data_directory))\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Data directory '{data_directory}' not found. Please check the path.\")\n",
    "\n",
    "# Load the styles CSV file with error handling\n",
    "styles_path = os.path.join(data_directory, 'styles.csv')\n",
    "try:\n",
    "    data = pd.read_csv(styles_path, on_bad_lines='skip')\n",
    "    print(\"\\nDataset loaded successfully after skipping problematic rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Inspect the structure of the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "data.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "df = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing images: 5\n",
      "\n",
      "Updated dataset after filtering missing images:\n",
      "      id  articleType                                         image_path\n",
      "0  15970       Shirts  D:/Jupyter_projects/Hey-Savi_assignment/fashio...\n",
      "1  39386        Jeans  D:/Jupyter_projects/Hey-Savi_assignment/fashio...\n",
      "2  59263      Watches  D:/Jupyter_projects/Hey-Savi_assignment/fashio...\n",
      "3  21379  Track Pants  D:/Jupyter_projects/Hey-Savi_assignment/fashio...\n",
      "4  53759      Tshirts  D:/Jupyter_projects/Hey-Savi_assignment/fashio...\n",
      "\n",
      "Number of unique product categories (classes): 142\n",
      "Classes: ['Shirts' 'Jeans' 'Watches' 'Track Pants' 'Tshirts' 'Socks' 'Casual Shoes'\n",
      " 'Belts' 'Flip Flops' 'Handbags' 'Tops' 'Bra' 'Sandals' 'Shoe Accessories'\n",
      " 'Sweatshirts' 'Deodorant' 'Formal Shoes' 'Bracelet' 'Lipstick' 'Flats'\n",
      " 'Kurtas' 'Waistcoat' 'Sports Shoes' 'Shorts' 'Briefs' 'Sarees'\n",
      " 'Perfume and Body Mist' 'Heels' 'Sunglasses' 'Innerwear Vests' 'Pendant'\n",
      " 'Nail Polish' 'Laptop Bag' 'Scarves' 'Rain Jacket' 'Dresses'\n",
      " 'Night suits' 'Skirts' 'Wallets' 'Blazers' 'Ring' 'Kurta Sets' 'Clutches'\n",
      " 'Shrug' 'Backpacks' 'Caps' 'Trousers' 'Earrings' 'Camisoles' 'Boxers'\n",
      " 'Jewellery Set' 'Dupatta' 'Capris' 'Lip Gloss' 'Bath Robe' 'Mufflers'\n",
      " 'Tunics' 'Jackets' 'Trunk' 'Lounge Pants' 'Face Wash and Cleanser'\n",
      " 'Necklace and Chains' 'Duffel Bag' 'Sports Sandals'\n",
      " 'Foundation and Primer' 'Sweaters' 'Free Gifts' 'Trolley Bag'\n",
      " 'Tracksuits' 'Swimwear' 'Shoe Laces' 'Fragrance Gift Set' 'Bangle'\n",
      " 'Nightdress' 'Ties' 'Baby Dolls' 'Leggings' 'Highlighter and Blush'\n",
      " 'Travel Accessory' 'Kurtis' 'Mobile Pouch' 'Messenger Bag' 'Lip Care'\n",
      " 'Face Moisturisers' 'Compact' 'Eye Cream' 'Accessory Gift Set'\n",
      " 'Beauty Accessory' 'Jumpsuit' 'Kajal and Eyeliner' 'Water Bottle'\n",
      " 'Suspenders' 'Lip Liner' 'Robe' 'Salwar and Dupatta' 'Patiala'\n",
      " 'Stockings' 'Eyeshadow' 'Headband' 'Tights' 'Nail Essentials' 'Churidar'\n",
      " 'Lounge Tshirts' 'Face Scrub and Exfoliator' 'Lounge Shorts' 'Gloves'\n",
      " 'Mask and Peel' 'Wristbands' 'Tablet Sleeve' 'Ties and Cufflinks'\n",
      " 'Footballs' 'Stoles' 'Shapewear' 'Nehru Jackets' 'Salwar' 'Cufflinks'\n",
      " 'Jeggings' 'Hair Colour' 'Concealer' 'Rompers' 'Body Lotion' 'Sunscreen'\n",
      " 'Booties' 'Waist Pouch' 'Hair Accessory' 'Rucksacks' 'Basketballs'\n",
      " 'Lehenga Choli' 'Clothing Set' 'Mascara' 'Toner' 'Cushion Covers'\n",
      " 'Key chain' 'Makeup Remover' 'Lip Plumper' 'Umbrellas'\n",
      " 'Face Serum and Gel' 'Hat' 'Mens Grooming Kit' 'Rain Trousers'\n",
      " 'Body Wash and Scrub' 'Ipad']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add a column for image file paths\n",
    "data['image_path'] = data['id'].apply(lambda x: os.path.join(data_directory, 'images', f\"{x}.jpg\"))\n",
    "\n",
    "# Check if all image files exist\n",
    "data['image_exists'] = data['image_path'].apply(lambda x: os.path.exists(x))\n",
    "missing_images = data[~data['image_exists']]\n",
    "print(f\"Number of missing images: {len(missing_images)}\")\n",
    "\n",
    "# Filter out rows with missing images\n",
    "data = data[data['image_exists']]\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"\\nUpdated dataset after filtering missing images:\")\n",
    "print(data[['id', 'articleType', 'image_path']].head())\n",
    "\n",
    "# Get unique classes for 'articleType'\n",
    "classes = data['articleType'].unique()\n",
    "print(f\"\\nNumber of unique product categories (classes): {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully after skipping problematic rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svaid\\AppData\\Local\\Temp\\ipykernel_24592\\3267764868.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['image_path'] = filtered_data['id'].apply(lambda x: os.path.join(data_directory, 'images', f\"{x}.jpg\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canny edge detection applied and saved for topwear images.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset metadata\n",
    "data_directory = 'fashion-dataset'\n",
    "styles_path = os.path.join(data_directory, 'styles.csv')\n",
    "try:\n",
    "    data = pd.read_csv(styles_path, on_bad_lines='skip')\n",
    "    print(\"\\nDataset loaded successfully after skipping problematic rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "# Filter for topwear images\n",
    "filtered_data = data[data['subCategory'] == 'Topwear']\n",
    "\n",
    "# Apply Canny edge detection to enhance neckline features\n",
    "def apply_canny_edge(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        return None  # Handle missing or unreadable images\n",
    "    edges = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "    return edges\n",
    "\n",
    "# Process all topwear images\n",
    "filtered_data['image_path'] = filtered_data['id'].apply(lambda x: os.path.join(data_directory, 'images', f\"{x}.jpg\"))\n",
    "output_directory = os.path.join(data_directory, 'processed_images')\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for idx, row in filtered_data.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    edges = apply_canny_edge(image_path)\n",
    "    if edges is not None:\n",
    "        output_path = os.path.join(output_directory, f\"{row['id']}_edges.jpg\")\n",
    "        cv2.imwrite(output_path, edges)\n",
    "\n",
    "print(\"Canny edge detection applied and saved for topwear images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15398 unlabeled images.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "# Define transformations (resize and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load processed images with custom dataset loader\n",
    "image_dir = 'fashion-dataset/processed_images'\n",
    "dataset = UnlabeledDataset(image_dir=image_dir, transform=transform)\n",
    "\n",
    "print(f\"Loaded {len(dataset)} unlabeled images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\svaid/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "dino_model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "dino_model.eval()\n",
    "\n",
    "# Define image transformations for DINO\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),   # Resize image\n",
    "    T.ToTensor(),           # Convert to tensor\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 15398 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def extract_features(image_path, model, transform):\n",
    "    \"\"\"\n",
    "    Extract feature vector from an image using DINO.\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model (torch.nn.Module): Pre-trained DINO model.\n",
    "        transform (torchvision.transforms.Compose): Transformations for preprocessing.\n",
    "    Returns:\n",
    "        np.ndarray: Feature vector extracted from the image.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(image)  # Get feature vector\n",
    "    \n",
    "    return features.squeeze().cpu().numpy()  # Convert to NumPy array\n",
    "\n",
    "# Directory containing processed images (Canny edge-detected)\n",
    "PROCESSED_IMAGE_DIR = 'fashion-dataset/processed_images'\n",
    "\n",
    "# Define transformations for DINO\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match DINO input size\n",
    "    transforms.ToTensor(),         # Convert to tensor\n",
    "])\n",
    "\n",
    "# Iterate through all processed images in the directory\n",
    "features = []\n",
    "for img_file in os.listdir(PROCESSED_IMAGE_DIR):\n",
    "    img_path = os.path.join(PROCESSED_IMAGE_DIR, img_file)\n",
    "    if os.path.isfile(img_path):  # Ensure it's a file\n",
    "        features.append(extract_features(img_path, dino_model, transform))\n",
    "\n",
    "# Convert features list to NumPy array for clustering or further processing\n",
    "features = np.array(features)\n",
    "print(f\"Extracted features for {len(features)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
